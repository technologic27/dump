{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runLSTM import buildRunLSTM\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv1D,MaxPooling1D,UpSampling1D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/traindata_01.pkl\", \"rb\") as input_file:\n",
    "    generated_data = pickle.load(input_file)\n",
    "\n",
    "list_tuples = [x for x in generated_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = buildRunLSTM()\n",
    "X, y, max_features, maxlen, labels = b.read_data(list_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "#test_data = scaler.transform(X_malicious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, y_train, y_test, _, label_test = train_test_split(X, y, labels, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set (images) shape: {shape}\".format(shape=train_data.shape))\n",
    "print(\"Testing set (images) shape: {shape}\".format(shape=test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'Normal',\n",
    " 1: 'DGA',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtype, test_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
    "                                                             train_data,\n",
    "                                                             test_size=0.2,\n",
    "                                                             random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.reshape(train_X, (len(train_X), maxlen, 1))\n",
    "valid_X = np.reshape(valid_X, (len(valid_X), maxlen, 1))\n",
    "train_ground = np.reshape(train_ground, (len(train_ground), maxlen, 1))\n",
    "valid_ground = np.reshape(valid_ground, (len(valid_ground), maxlen, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "inChannel = 1\n",
    "x, y = 1, 59\n",
    "input_img = Input(shape = (59, 1))\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 1 X 59 (wide and thin)\n",
    "    conv1 = Conv1D(3, 3, activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv1D(3, 3, activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=1)(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv1D(6, 3, activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv1D(6, 3, activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    #conv2 = MaxPooling1D(pool_size=1)(conv2) #7 x 7 x 64\n",
    "    #conv3 = Conv1D(9, 3, activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    #conv3 = BatchNormalization()(conv3)\n",
    "    #conv3 = Conv1D(9, 3, activation='relu', padding='same')(conv3)\n",
    "    #conv3 = BatchNormalization()(conv3)\n",
    "    #conv4 = Conv1D(12, 3, activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    #conv4 = BatchNormalization()(conv4)\n",
    "    #conv4 = Conv1D(12, 3, activation='relu', padding='same')(conv4)\n",
    "    #conv4 = BatchNormalization()(conv4)\n",
    "    return conv2\n",
    "\n",
    "def decoder(conv2):    \n",
    "    #decoder\n",
    "    #conv5 = Conv1D(9, 3, activation='relu', padding='same')(conv4) #7 x 7 x 128\n",
    "    #conv5 = BatchNormalization()(conv5)\n",
    "    #conv5 = Conv1D(9, 3, activation='relu', padding='same')(conv5)\n",
    "    #conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv1D(6, 3, activation='relu', padding='same')(conv2) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv1D(6, 3, activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    #up1 = UpSampling1D(2)(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv1D(3, 3, activation='relu', padding='same')(conv6) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv1D(3, 3, activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    #up2 = UpSampling1D(2)(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv1D(1, 3, activation='sigmoid', padding='same')(conv7) # 28 x 28 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoder(encoder(input_img)))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train = autoencoder.fit(train_X[0:10000], train_ground[0:10000], batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X[0:1000], valid_ground[0:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
